{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拿到主页面源代码，找到子页面的href\n",
    "# 找到图片下载链接\n",
    "# 下载图片\n",
    "import time\n",
    "import requests\n",
    "import bs4 as BeautifulSoup\n",
    "url = 'https://www.umei.cc/bizhitupian/weimeibizhi/'\n",
    "resp = requests.get(url)\n",
    "resp.encoding = 'utf-8' # 处理乱码\n",
    "\n",
    "# 源代码交给bs\n",
    "main_page = BeautifulSoup(resp.text, 'html.parser')\n",
    "alist = main_page.find('div', class_= 'Typelist').find_all('a')\n",
    "\n",
    "for a in alist:\n",
    "    href = a.get('href') # 直接通过get拿到属性值\n",
    "    # 拿到子页面源代码\n",
    "    child_page_resp = requests.get(href)\n",
    "    child_page_resp.encoding = 'utf-8'\n",
    "    child_page_text = child_page_resp.text\n",
    "    # 拿到图片的下载途径\n",
    "    child_page = BeautifulSoup(child_page_text, 'html_parser')\n",
    "    p = child_page.find('p', align = 'center')\n",
    "    img = p.find('img')\n",
    "    src = img.get('src')\n",
    "    # 下载图片\n",
    "    img_response = requests.get(src)\n",
    "    # img_response.content # 这里拿到的是字节\n",
    "    img_name = src.split('/')[-1] # 拿到url的最后一个/以后的内容\n",
    "    with open('img/'+img_name, mode='wb') as f :\n",
    "        f.write(img_response.content) # 图片内容写入文件\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "resp.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
